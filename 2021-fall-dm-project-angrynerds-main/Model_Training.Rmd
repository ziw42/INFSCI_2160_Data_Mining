---
title: "Model Training"
author: "Zian Wang"
date: "2021/12/1"
output: html_document
---

## Introduction

This file is used to 1. divide the pre-processed data into training and test data. 2. do oversampling. 3. build the term-document matrix. 4. train the model. 5. Output the analysis of the performances of the models.

## Code

Setting trunk.

```{r, warning=FALSE}
library("dplyr") ## for making the data frames
library("RTextTools")
library("stringdist")

theme_set(theme_bw()) # change the default ggplot theme to black-and-white

knitr::opts_chunk$set(
  echo=T, ## show your R code chunk
  message = F, ## hide the message
  warning = F, ## hide the warning
  autodep = T ## make sure your separate code chunks can find the dependencies (from other code chunk)
)
```


Read the files. We do not need this trunk now, we can just read the text and the label files.

```{r, warning=TRUE}
##setwd("A:/Data_Mining/2021-fall-dm-project-angrynerds")
Sys.setlocale(category = "LC_ALL", locale = "us")
readFile <- function(filename, num) {
  text <- c()
  labels <- c()
  con <- file(filename, "r")
  line = readLines(con, n=1)
  while(length(line) != 0) {
    
    line <- gsub("\\t", "", line)
    line <- gsub("\\n", "", line)
    if(nchar(line) >= 60 && nchar(line) <= 500) {
      text <- c(text, line)
    }
    line <- readLines(con, n=1)
  }
  close(con)
  return(text)
}

text <- c()
for(i in list.files("./data")) {
  text <- c(text, readFile(paste("./data/", i, sep = "")))
}
```

Read the text and label files. Divide the data into training and test parts. Do oversampling.

```{r}
### Read the data stored in files. If you do not have these files, do not run.
label <- readRDS("./text_label/label.rds")
text <- readRDS("./text_label/text.rds")

### Set the seed to make the result reproducible.
set.seed(123)

### Make the text a data frame.
sub_text <- cbind(text, as.factor(label))
colnames(sub_text) <- c("Text", "Label")
sub_text <- as.data.frame(sub_text)
sub_text <- arrange(sub_text,Label)
summary(as.factor(sub_text$Label))

### Define the oversampling function.
over_sampling <- function(sub_text, index, times) {
  temp <- data.frame()
  i <- 0
  while(i < times) {
    temp <- rbind(temp, sub_text[min(index): max(index),])
    i = i+1
  }
  return(temp)
}

### I also defined a undersampling function. But we do not need this in the project.
under_sampling <- function(index, times) {
  temp_label <- sample(min(index):max(index), floor(length(index) * times))
  return(sub_text[temp_label,])
}

### Divide the test data.
test_data <- data.frame()
### --- 80% of the data is the training data. The rest 20% of the data is test data.
proportion <- 0.2
### This function can divide the data into training and test data.
get_test <- function(index, proportion) {
  test_index <- sample(index, proportion * length(index))
  return(test_index)
}

### Attribute for oversampling. I multiply each problematic class 50 times.
times <- 50

### Define a wrapper function that divide the data and do oversampling.
prepare_data <- function(sub_text, times, proportion) {
  t <- 1
  test_data <- data.frame()
  problematic_data <- data.frame()
  while(t < 5) {
    label <- which(sub_text$Label==t)
    test_index <- get_test(label, proportion)
    test_data <- rbind(test_data, sub_text[test_index,])
    sub_text <- sub_text[-test_index,]
    label <- which(sub_text$Label==t)
    temp <- over_sampling(sub_text, label, times)
    print(nrow(temp))
    problematic_data <- rbind(problematic_data, temp)
    t = t+1
  }
  label_5 <- which(sub_text$Label==5)
  test_index <- get_test(label_5, proportion)
  test_data <- rbind(test_data, sub_text[test_index,])
  sub_text <- sub_text[-test_index,]
  t <- 6
  while(t <= 7) {
    label <- which(sub_text$Label==t)
    test_index <- get_test(label, proportion)
    test_data <- rbind(test_data, sub_text[test_index,])
    sub_text <- sub_text[-test_index,]
    label <- which(sub_text$Label==t)
    temp <- over_sampling(sub_text, label, times)
    problematic_data <- rbind(problematic_data, temp)
    t = t+1
  }
  non_problematic_data <- sub_text %>% filter(Label == 5)
  sub_text <- rbind(problematic_data, non_problematic_data)
  sub_text <- sub_text[sample(nrow(sub_text)),]
  sub_text <- rbind(test_data, sub_text)
  sign <- data.frame()
  ### Store the length of the test data in the last row of the data frame.
  sign[1,1] <- "length of test_data is"
  sign[1,2] <- nrow(test_data)
  colnames(sign) <- c("Text", "Label")
  sub_text <- rbind(sub_text, sign)
}

### sub_text is the data ready for training.
sub_text <- prepare_data(sub_text, times, proportion)
```

The function that can assign the indexes of training data and test data.

```{r}
### Input: The start and end indexes of the testing data, the rest data will be used to train. If mode=train, the output will be the indexes of training data, if mode=test, the output will be the indexes of test data.

assign_indexes <- function(start, end, mode){
  if(mode == "train") {
    return(c(1:(start-1), (end+1):nrow(sub_text)))
  }
  else {
    return(c(start: end))
  }
}
```

Build the matrix and the container:

```{r}
### Read the length of the test data.
length_of_test <- as.numeric(sub_text[nrow(sub_text),"Label"])
length_of_test <- as.integer(length_of_test)
### Remove the row that stores the length of the test data because we do not need it anymore.
sub_text <- sub_text[-nrow(sub_text),]

### Build the term-document matrix, here I assign the removeSparseTerms input to remover the sparse terms.
doc_matrix <- create_matrix(sub_text$Text, language="english", removeNumbers=TRUE,
stemWords=TRUE, removePunctuation = TRUE, removeSparseTerms = .998)

### Build the container.
container <- create_container(doc_matrix, sub_text$Label[1:nrow(sub_text)], trainSize=(length_of_test+1):nrow(sub_text), testSize=1:length_of_test, virgin=FALSE)

### Save the data and the container, so we do not need to build them every time.
saveRDS(sub_text, "./text_label/sub_text_final.rds")
saveRDS(container, "./analysis/container_final.rds")
```

Training models

Warning: some models will take very long time to train, for example, BAGGING and RF. Also, RF model will be highly likely to overflow your memory, so please use "memory.size()" function to enlargh the memory that your OS assigned to RStudio.

If you have already had the model files, you do not need to run this trunk. You can run the next trunk to simply read the model files.

```{r}
### Train the models.
SVM <- train_model(container,"SVM")
SLDA <- train_model(container,"SLDA")
BOOSTING <- train_model(container,"BOOSTING")
BAGGING <- train_model(container,"BAGGING")
RF <- train_model(container,"RF")
NNET <- train_model(container,"NNET")
TREE <- train_model(container,"TREE")

### Save the models to the disk. Here we do not save the RF model file because it can reach about 800MB, loading it will overflow the memory so we actually cannot use that.
saveRDS(SLDA, "./models/SLDA_FINAL.rds")
saveRDS(SVM, "./models/SVM_FINAL.rds")
saveRDS(BOOSTING, "./models/BOOSTING_FINAL.rds")
saveRDS(BAGGING, "./models/NNET_FINAL.rds")
saveRDS(BAGGING, "./models/RF_FINAL.rds")
saveRDS(BAGGING, "./models/TREE_FIANL.rds")
```

If you have already had the model files or the analytic file, you can use this trunk.

```{r}
### Read the models.
SLDA <- readRDS("./models/SLDA_FINAL.rds")
SVM <- readRDS("./models/SVM_FINAL.rds")
BOOSTING <- readRDS("./models/BOOSTING_FINAL.rds")
RF <- readRDS("./models/RF_FINAL.rds")
NNET <- readRDS("./models/NNET_FINAL.rds")
TREE <- readRDS("./models/TREE_FINAL.rds")

### Predict the test data.
SLDA_CLASSIFY <- classify_model(container, SLDA)
SVM_CLASSIFY <- classify_model(container, SVM)
BOOSTING_CLASSIFY <- classify_model(container, BOOSTING)
BAGGING_CLASSIFY <- classify_model(container, BAGGING)
RF_CLASSIFY <- classify_model(container, RF)
NNET_CLASSIFY <- classify_model(container, NNET)
TREE_CLASSIFY <- classify_model(container, TREE)


### Analysis the performances of the models.
analytics <- create_analytics(container,
cbind(SVM_CLASSIFY, SLDA_CLASSIFY,
BOOSTING_CLASSIFY, BAGGING_CLASSIFY,RF_CLASSIFY, 
NNET_CLASSIFY, TREE_CLASSIFY))

### Or read the analytic file if you have.
analytics <- readRDS("./analysis/ANALYTICS_FINAL.rds")

### Output the analysis.
summary(analytics)
topic_summary <- analytics@label_summary
alg_summary <- analytics@algorithm_summary
ens_summary <-analytics@ensemble_summary
doc_summary <- analytics@document_summary

### Save the analysis to the disk.
saveRDS(analytics, "./analysis/ANALYTICS_FINAL.rds")
```
